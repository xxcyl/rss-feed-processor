{
    "Ear Hear": {
        "feed_title": "Ear Hear",
        "feed_link": "https://pubmed.ncbi.nlm.nih.gov/?sort=date&term=8005585%20%5BNLMID%5D&utm_content=8005585&fc=None&ff=20240625093644&utm_medium=rss&v=2.18.0.post9+e462414&utm_campaign=journals&utm_source=Other",
        "feed_updated": "Tue, 25 Jun 2024 13:36:45 +0000",
        "entries": [
            {
                "title": "International Consensus Statements on Intraoperative Testing for Cochlear Implantation Surgery",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38915137/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.918287",
                "summary": "CONCLUSIONS: A final core set of 24 consensus statements was generated, covering wide areas of intraoperative testing during CI surgery. These statements may provide utility as evidence-based guidelines to improve quality and achieve uniformity of surgical practice.",
                "full_content": "Ear Hear\n. 2024 Jun 25. doi: 10.1097/AUD.0000000000001526. Online ahead of print.\nABSTRACT\nOBJECTIVES: A wide variety of intraoperative tests are available in cochlear implantation. However, no consensus exists on which tests constitute the minimum necessary battery. We assembled an international panel of clinical experts to develop, refine, and vote upon a set of core consensus statements.\nDESIGN: A literature review was used to identify intraoperative tests currently used in the field and draft a set of provisional statements. For statement evaluation and refinement, we used a modified Delphi consensus panel structure. Multiple interactive rounds of voting, evaluation, and feedback were conducted to achieve convergence.\nRESULTS: Twenty-nine provisional statements were included in the original draft. In the first voting round, consensus was reached on 15 statements. Of the 14 statements that did not reach consensus, 12 were revised based on feedback provided by the expert practitioners, and 2 were eliminated. In the second voting round, 10 of the 12 revised statements reached a consensus. The two statements which did not achieve consensus were further revised and subjected to a third voting round. However, both statements failed to achieve consensus in the third round. In addition, during the final revision, one more statement was decided to be deleted due to overlap with another modified statement.\nCONCLUSIONS: A final core set of 24 consensus statements was generated, covering wide areas of intraoperative testing during CI surgery. These statements may provide utility as evidence-based guidelines to improve quality and achieve uniformity of surgical practice.\nPMID:\n38915137\n| DOI:\n10.1097/AUD.0000000000001526"
            },
            {
                "title": "Barriers to Meeting National Early Hearing Detection and Intervention Guidelines in a Diverse Patient Cohort",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38898551/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.918760",
                "summary": "CONCLUSIONS: A significant association between total number of ABRs and age at identification and intervention for children with hearing loss exists. Hispanic ethnicity was associated with delays in meeting milestones, further mediated by the number of ABRs, providing a potential avenue for intervention in addressing this disparity.",
                "full_content": "Ear Hear\n. 2024 Jun 20. doi: 10.1097/AUD.0000000000001534. Online ahead of print.\nABSTRACT\nOBJECTIVES: To determine our audiology clinics status in meeting the Joint Committee on Infant Hearing recommended 1-3-6 benchmarks for identification and intervention for congenital sensorineural hearing loss and identify those factors contributing to delay in identification and intervention.\nDESIGN: This is a retrospective case series. Children with sensorineural hearing loss who underwent auditory brainstem response (ABR) testing, hearing aid evaluation, or cochlear implant mapping at our tertiary pediatric medical center between January 2018 and December 2021 were included. Simple and multiple linear regression analyses were used to identify social, demographic, and health factors associated with primary outcomes, defined as age at hearing loss identification, age at intervention (here defined as amplification start), and interval between identification and intervention.\nRESULTS: Of 132 patients included, mean age was 2.4 years, 48% were male, and 51% were Hispanic. There was significant association between each Hispanic ethnicity (p = 0.005, p = 0.04, respectively), insurance type (p = 0.02, p = 0.001, respectively), and later age at identification and intervention. In multivariable analyses, Hispanic ethnicity was significantly associated with both delays in identification and intervention (p = 0.03 and p = 0.03, respectively), and public insurance was associated with delays in intervention (p = 0.01). In addition, the total number of ABRs was significantly associated with both older age of identification and intervention (p < 0.001, p < 0.001, respectively). Mediator analysis demonstrated that the effect of ethnicity on age at identification is mediated by the total number of ABRs performed.\nCONCLUSIONS: A significant association between total number of ABRs and age at identification and intervention for children with hearing loss exists. Hispanic ethnicity was associated with delays in meeting milestones, further mediated by the number of ABRs, providing a potential avenue for intervention in addressing this disparity.\nPMID:\n38898551\n| DOI:\n10.1097/AUD.0000000000001534"
            },
            {
                "title": "Trajectories of Hearing From Childhood to Adulthood",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38898547/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.919203",
                "summary": "CONCLUSIONS: We aim to use these findings to develop a foundational model of hearing trajectories. This will form the basis for identifying precursors, to be investigated in a subsequent series of analyses, that may protect against or exacerbate hearing-associated cognitive decline in the Dunedin Study cohort as they progress from mid-life to older age.",
                "full_content": "Ear Hear\n. 2024 Jun 20. doi: 10.1097/AUD.0000000000001542. Online ahead of print.\nABSTRACT\nOBJECTIVES: The Dunedin Multidisciplinary Health and Development Study provides a unique opportunity to document the progression of ear health and hearing ability within the same cohort of individuals from birth. This investigation draws on hearing data from 5 to 13 years and again at 45 years of age, to explore the associations between childhood hearing variables and hearing and listening ability at age 45.\nDESIGN: Multiple linear regression analyses were used to assess associations between childhood hearing (otological status and mid-frequency pure-tone average) and (a) age 45 peripheral hearing ability (mid-frequency pure-tone average and high-frequency pure-tone average), and (b) age 45 listening ability (listening in spatialized noise and subjective questionnaire on listening experiences). Sex, childhood socioeconomic status, and adult IQ were included in the model as covariates.\nRESULTS: Peripheral hearing and listening abilities at age 45 were consistently associated with childhood hearing acuity at mid-frequencies. Otological status was a moderate predicting factor for high-frequency hearing and utilization of spatial listening cues in adulthood.\nCONCLUSIONS: We aim to use these findings to develop a foundational model of hearing trajectories. This will form the basis for identifying precursors, to be investigated in a subsequent series of analyses, that may protect against or exacerbate hearing-associated cognitive decline in the Dunedin Study cohort as they progress from mid-life to older age.\nPMID:\n38898547\n| DOI:\n10.1097/AUD.0000000000001542"
            },
            {
                "title": "Listening Effort Measured With Pupillometry in Cochlear Implant Users Depends on Sound Level, But Not on the Signal to Noise Ratio When Using the Matrix Test",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38886888/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.919558",
                "summary": "CONCLUSIONS: The lack of a significant effect of varying SNR on PPD suggests that the Matrix test may not be a feasible speech test for measuring listening effort with pupillometric measures for CI users. A rating test appeared more promising in this population, corroborating earlier reports that subjective measures may reflect different dimensions of listening effort than pupil dilation. Establishing the SNR by varying speech or noise level can have subtle, but significant effects on measures...",
                "full_content": "Ear Hear\n. 2024 Jun 18. doi: 10.1097/AUD.0000000000001529. Online ahead of print.\nABSTRACT\nOBJECTIVES: We investigated whether listening effort is dependent on task difficulty for cochlear implant (CI) users when using the Matrix speech-in-noise test. To this end, we measured peak pupil dilation (PPD) at a wide range of signal to noise ratios (SNR) by systematically changing the noise level at a constant speech level, and vice versa.\nDESIGN: A group of mostly elderly CI users performed the Dutch/Flemish Matrix test in quiet and in multitalker babble at different SNRs. SNRs were set relative to the speech-recognition threshold (SRT), namely at SRT, and 5 and 10 dB above SRT (0 dB, +5 dB, and +10 dB re SRT). The latter 2 conditions were obtained by either varying speech level (at a fixed noise level of 60 dBA) or by varying noise level (with a fixed speech level). We compared these PPDs with those of a group of typical hearing (TH) listeners. In addition, listening effort was assessed with subjective ratings on a Likert scale.\nRESULTS: PPD for the CI group did not significantly depend on SNR, whereas SNR significantly affected PPDs for TH listeners. Subjective effort ratings depended significantly on SNR for both groups. For CI users, PPDs were significantly larger, and effort was rated higher when speech was varied, and noise was fixed for CI users. By contrast, for TH listeners effort ratings were significantly higher and performance scores lower when noise was varied, and speech was fixed.\nCONCLUSIONS: The lack of a significant effect of varying SNR on PPD suggests that the Matrix test may not be a feasible speech test for measuring listening effort with pupillometric measures for CI users. A rating test appeared more promising in this population, corroborating earlier reports that subjective measures may reflect different dimensions of listening effort than pupil dilation. Establishing the SNR by varying speech or noise level can have subtle, but significant effects on measures of listening effort, and these effects can differ between TH listeners and CI users.\nPMID:\n38886888\n| DOI:\n10.1097/AUD.0000000000001529"
            },
            {
                "title": "The Effort of Repairing a Misperceived Word Can Impair Perception of Following Words, Especially for Listeners With Cochlear Implants",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38886880/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.919916",
                "summary": "CONCLUSIONS: For CI listeners, the effort of needing to repair misperceptions in a sentence can last long enough to interfere with words that follow the sentence. This pattern could pose a serious problem for regular communication but would go overlooked in typical testing with single utterances, where a listener has a chance to repair misperceptions before responding. Carryover effort was not predictable by basic intelligibility scores, but can be revealed in behavioral data when sentences are...",
                "full_content": "Ear Hear\n. 2024 Jun 18. doi: 10.1097/AUD.0000000000001537. Online ahead of print.\nABSTRACT\nOBJECTIVES: In clinical and laboratory settings, speech recognition is typically assessed in a way that cannot distinguish accurate auditory perception from misperception that was mentally repaired or inferred from context. Previous work showed that the process of repairing misperceptions elicits greater listening effort, and that this elevated effort lingers well after the sentence is heard. That result suggests that cognitive repair strategies might appear successful when testing a single utterance but fail for everyday continuous conversational speech. The present study tested the hypothesis that the effort of repairing misperceptions has the consequence of carrying over to interfere with perception of later words after the sentence.\nDESIGN: Stimuli were open-set coherent sentences that were presented intact or with a word early in the sentence replaced with noise, forcing the listener to use later context to mentally repair the missing word. Sentences were immediately followed by digit triplets, which served to probe carryover effort from the sentence. Control conditions allowed for the comparison to intact sentences that did not demand mental repair, as well as to listening conditions that removed the need to attend to the post-sentence stimuli, or removed the post-sentence digits altogether. Intelligibility scores for the sentences and digits were accompanied by time-series measurements of pupil dilation to assess cognitive load during the task, as well as subjective rating of effort. Participants included adults with cochlear implants (CIs), as well as an age-matched group and a younger group of listeners with typical hearing for comparison.\nRESULTS: For the CI group, needing to repair a missing word during a sentence resulted in more errors on the digits after the sentence, especially when the repair process did not result in a coherent sensible perception. Sentences that needed repair also contained more errors on the words that were unmasked. All groups showed substantial increase of pupil dilation when sentences required repair, even when the repair was successful. Younger typical hearing listeners showed clear differences in moment-to-moment allocation of effort in the different conditions, while the other groups did not.\nCONCLUSIONS: For CI listeners, the effort of needing to repair misperceptions in a sentence can last long enough to interfere with words that follow the sentence. This pattern could pose a serious problem for regular communication but would go overlooked in typical testing with single utterances, where a listener has a chance to repair misperceptions before responding. Carryover effort was not predictable by basic intelligibility scores, but can be revealed in behavioral data when sentences are followed immediately by extra probe words such as digits.\nPMID:\n38886880\n| DOI:\n10.1097/AUD.0000000000001537"
            },
            {
                "title": "Subjective Speech Intelligibility Drives Noise-Tolerance Domain Use During the Tracking of Noise-Tolerance Test",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38880961/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.920302",
                "summary": "CONCLUSIONS: The domain criteria used by listeners were driven by their subjective speech intelligibility regardless of their hearing status (i.e., NH versus HI). In general, when subjective intelligibility was poor, the domains of speech interference and loudness were weighed the heaviest. As subjective intelligibility improved, the weightings on annoyance and distraction increased. Furthermore, a listener's criterion for >90% subjective speech understanding at the TNTAve may allow one to...",
                "full_content": "Ear Hear\n. 2024 Jun 17. doi: 10.1097/AUD.0000000000001536. Online ahead of print.\nABSTRACT\nOBJECTIVES: Recently, the Noise-Tolerance Domains Test (NTDT) was applied to study the noise-tolerance domains used by young normal-hearing (NH) listeners during noise acceptance decisions. In this study, we examined how subjective speech intelligibility may drive noise acceptance decisions by applying the NTDT on NH and hearing-impaired (HI) listeners at the signal to noise ratios (SNRs) around the Tracking of Noise-Tolerance (TNT) thresholds.\nDESIGN: A single-blind, within-subjects design with 22 NH and 17 HI older adults was followed. Listeners completed the TNT to determine the average noise acceptance threshold (TNTAve). Then, listeners completed the NTDT at the SNRs of 0, ±3 dB (re: TNTAve) to estimate the weighted noise-tolerance domain ratings (WNTDRs) for each domain criterion. Listeners also completed the Objective and Subjective Intelligibility Difference (OSID) Test to establish the individual intelligibility performance-intensity (P-I) functions of the TNT materials. All test measures were conducted at 75 and 82 dB SPL speech input levels. NH and HI listeners were tested in the unaided mode. The HI listeners were also tested using a study hearing aid. The WNTDRs were plotted against subjective speech intelligibilities extrapolated from individual P-I of the OSID at the SNRs corresponding to NTDT test conditions. Listeners were grouped according to their most heavily weighed domain and a regression analysis was performed against listener demographics as well as TNT and OSID performances to determine which variable(s) affected listener grouping.\nRESULTS: Three linear mixed effects (LMEs) models were used to examine whether WNTDRs changed with subjective speech intelligibility. All three LMEs found significant fixed effects of domain criteria, subjective intelligibility, and speech input level on WNTDRs. In general, heavier weights were assigned to speech interference and loudness domains at poorer intelligibility levels (<50%) with reversals to distraction and annoyance at higher intelligibility levels (>80%). The comparison between NH and HI-unaided showed that NH listeners assigned greater weights to loudness than the HI-unaided listeners. The comparison between NH and HI-aided groups showed similar weights between groups. The comparison between HI-unaided and HI-aided found that HI listeners assigned lower weights to speech interference and greater weights to loudness when tested in aided compared with unaided modes. In all comparisons, loudness was weighed heavier at the 82 dB SPL input level than at the 75 dB SPL input level with greater weights to annoyance in the NH versus HI-unaided comparison and lower weights to distraction in the HI-aided versus HI-unaided comparison. A generalized linear model determined that listener grouping was best accounted for by subjective speech intelligibility estimated at TNTAve.\nCONCLUSIONS: The domain criteria used by listeners were driven by their subjective speech intelligibility regardless of their hearing status (i.e., NH versus HI). In general, when subjective intelligibility was poor, the domains of speech interference and loudness were weighed the heaviest. As subjective intelligibility improved, the weightings on annoyance and distraction increased. Furthermore, a listener's criterion for >90% subjective speech understanding at the TNTAve may allow one to profile the listener.\nPMID:\n38880961\n| DOI:\n10.1097/AUD.0000000000001536"
            },
            {
                "title": "A Multimodal Approach to Measuring Listening Effort: A Systematic Review on the Effects of Auditory Task Demand on Physiological Measures and Their Relationship",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38880960/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.920649",
                "summary": "CONCLUSIONS: The included studies showed that most of the physiological measures either show no effect to auditory task demand manipulations or a consistent effect in the expected direction. For example, pupil dilation increased, pre-ejection period decreased, and skin conductance level increased with increasing auditory task demand. Most of the relationships between the responses of these physiological measures were nonsignificant or weak. The physiological measures varied in their sensitivity...",
                "full_content": "Ear Hear\n. 2024 Jun 17. doi: 10.1097/AUD.0000000000001508. Online ahead of print.\nABSTRACT\nOBJECTIVES: Listening effort involves the mental effort required to perceive an auditory stimulus, for example in noisy environments. Prolonged increased listening effort, for example due to impaired hearing ability, may increase risk of health complications. It is therefore important to identify valid and sensitive measures of listening effort. Physiological measures have been shown to be sensitive to auditory task demand manipulations and are considered to reflect changes in listening effort. Such measures include pupil dilation, alpha power, skin conductance level, and heart rate variability. The aim of the current systematic review was to provide an overview of studies to listening effort that used multiple physiological measures. The two main questions were: (1) what is the effect of changes in auditory task demand on simultaneously acquired physiological measures from various modalities? and (2) what is the relationship between the responses in these physiological measures?\nDESIGN: Following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, relevant articles were sought in PubMed, PsycInfo, and Web of Science and by examining the references of included articles. Search iterations with different combinations of psychophysiological measures were performed in conjunction with listening effort-related search terms. Quality was assessed using the Appraisal Tool for Cross-Sectional Studies.\nRESULTS: A total of 297 articles were identified from three databases, of which 27 were included. One additional article was identified from reference lists. Of the total 28 included articles, 16 included an analysis regarding the relationship between the physiological measures. The overall quality of the included studies was reasonable.\nCONCLUSIONS: The included studies showed that most of the physiological measures either show no effect to auditory task demand manipulations or a consistent effect in the expected direction. For example, pupil dilation increased, pre-ejection period decreased, and skin conductance level increased with increasing auditory task demand. Most of the relationships between the responses of these physiological measures were nonsignificant or weak. The physiological measures varied in their sensitivity to auditory task demand manipulations. One of the identified knowledge gaps was that the included studies mostly used tasks with high-performance levels, resulting in an underrepresentation of the physiological changes at lower performance levels. This makes it difficult to capture how the physiological responses behave across the full psychometric curve. Our results support the Framework for Understanding Effortful Listening and the need for a multimodal approach to listening effort. We furthermore discuss focus points for future studies.\nPMID:\n38880960\n| DOI:\n10.1097/AUD.0000000000001508"
            },
            {
                "title": "Electrocochleography-Based Tonotopic Map: II. Frequency-to-Place Mismatch Impacts Speech-Perception Outcomes in Cochlear Implant Recipients",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38880958/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.921409",
                "summary": "CONCLUSIONS: Comparison of ECochG-BF derived tonotopic electrode maps to the frequency allocation tables reveals substantial mismatch, explaining 26.0% of the variability in CI performance in quiet. Closer examination of the mismatch shows that basally shifted maps at high frequencies demonstrate superior performance at 3 months compared with those with apically shifted maps (toward Greenwood and Stakhovskaya et al.). The implications of these results suggest that electrophysiological-based...",
                "full_content": "Ear Hear\n. 2024 Jun 17. doi: 10.1097/AUD.0000000000001528. Online ahead of print.\nABSTRACT\nOBJECTIVES: Modern cochlear implants (CIs) use varying-length electrode arrays inserted at varying insertion angles within variably sized cochleae. Thus, there exists an opportunity to enhance CI performance, particularly in postlinguistic adults, by optimizing the frequency-to-place allocation for electrical stimulation, thereby minimizing the need for central adaptation and plasticity. There has been interest in applying Greenwood or Stakhovskaya et al. function (describing the tonotopic map) to postoperative imaging of electrodes to improve frequency allocation and place coding. Acoustically-evoked electrocochleography (ECochG) allows for electrophysiologic best-frequency (BF) determination of CI electrodes and the potential for creating a personalized frequency allocation function. The objective of this study was to investigate the correlation between early speech-perception performance and frequency-to-place mismatch.\nDESIGN: This retrospective study included 50 patients who received a slim perimodiolar electrode array. Following electrode insertion, five acoustic pure-tone stimuli ranging from 0.25 to 2 kHz were presented, and electrophysiological measurements were collected across all 22 electrode contacts. Cochlear microphonic tuning curves were subsequently generated for each stimulus frequency to ascertain the BF electrode or the location corresponding to the maximum response amplitude. Subsequently, we calculated the difference between the stimulus frequency and the patient's CI map's actual frequency allocation at each BF electrode, reflecting the frequency-to-place mismatch. BF electrocochleography-total response (BF-ECochG-TR), a measure of cochlear health, was also evaluated for each subject to control for the known impact of this measure on performance.\nRESULTS: Our findings showed a moderate correlation (r = 0.51; 95% confidence interval: 0.23 to 0.76) between the cumulative frequency-to-place mismatch, as determined using the ECochG-derived BF map (utilizing 500, 1000, and 2000 Hz), and 3-month performance on consonant-nucleus-consonant words (N = 38). Larger positive mismatches, shifted basal from the BF map, led to enhanced speech perception. Incorporating BF-ECochG-TR, total mismatch, and their interaction in a multivariate model explained 62% of the variance in consonant-nucleus-consonant word scores at 3 months. BF-ECochG-TR as a standalone predictor tended to overestimate performance for subjects with larger negative total mismatches and underestimated the performance for those with larger positive total mismatches. Neither cochlear diameter, number of cochlear turns, nor apical insertion angle accounted for the variability in total mismatch.\nCONCLUSIONS: Comparison of ECochG-BF derived tonotopic electrode maps to the frequency allocation tables reveals substantial mismatch, explaining 26.0% of the variability in CI performance in quiet. Closer examination of the mismatch shows that basally shifted maps at high frequencies demonstrate superior performance at 3 months compared with those with apically shifted maps (toward Greenwood and Stakhovskaya et al.). The implications of these results suggest that electrophysiological-based frequency reallocation might lead to enhanced speech-perception performance, especially when compared with conventional manufacturer maps or anatomic-based mapping strategies. Future research, exploring the prospective use of ECochG-based mapping techniques for frequency allocation is underway.\nPMID:\n38880958\n| DOI:\n10.1097/AUD.0000000000001528"
            },
            {
                "title": "Uses of Linguistic Context in Speech Listening: Does Acquired Hearing Loss Lead to Reduced Engagement of Prediction?",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38880953/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.921688",
                "summary": "Research investigating the complex interplay of cognitive mechanisms involved in speech listening for people with hearing loss has been gaining prominence. In particular, linguistic context allows the use of several cognitive mechanisms that are not well distinguished in hearing science, namely those relating to \"postdiction\", \"integration\", and \"prediction\". We offer the perspective that an unacknowledged impact of hearing loss is the differential use of predictive mechanisms relative to...",
                "full_content": "Ear Hear\n. 2024 Jun 17. doi: 10.1097/AUD.0000000000001515. Online ahead of print.\nABSTRACT\nResearch investigating the complex interplay of cognitive mechanisms involved in speech listening for people with hearing loss has been gaining prominence. In particular, linguistic context allows the use of several cognitive mechanisms that are not well distinguished in hearing science, namely those relating to \"postdiction\", \"integration\", and \"prediction\". We offer the perspective that an unacknowledged impact of hearing loss is the differential use of predictive mechanisms relative to age-matched individuals with normal hearing. As evidence, we first review how degraded auditory input leads to reduced prediction in people with normal hearing, then consider the literature exploring context use in people with acquired postlingual hearing loss. We argue that no research on hearing loss has directly assessed prediction. Because current interventions for hearing do not fully alleviate difficulty in conversation, and avoidance of spoken social interaction may be a mediator between hearing loss and cognitive decline, this perspective could lead to greater understanding of cognitive effects of hearing loss and provide insight regarding new targets for intervention.\nPMID:\n38880953\n| DOI:\n10.1097/AUD.0000000000001515"
            },
            {
                "title": "Validation of the Chinese Version of the Speech, Spatial, and Qualities of Hearing Scale for Parents and Children",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38831494/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.922050",
                "summary": "CONCLUSIONS: Both C-SSQ-P and C-SSQ-C are reliable and valid for assessing HL in children and adolescents. The C-SSQ-P is applicable in evaluating young children aged 3 to 6.9 years after a 7-day observation period, while the C-SSQ-C is appropriate for children and adolescents aged 7 to 18 years.",
                "full_content": "Ear Hear\n. 2024 Jun 4. doi: 10.1097/AUD.0000000000001525. Online ahead of print.\nABSTRACT\nOBJECTIVES: To translate and validate the Chinese version of the Speech, Spatial, and Qualities of Hearing Scale (SSQ) for children with hearing impairment (C-SSQ-C) and for their parents (C-SSQ-P).\nDESIGN: We translated the SSQ for children into Chinese and verified its readability and comprehensibility. A total of 105 participants with moderate-to-profound hearing loss (HL) and 54 with normal hearing were enrolled in the validation process. The participants with HL were fitted with bilateral hearing aids, bimodal hearing, or bilateral cochlear implants. The C-SSQ-P was administered to the parents of participants aged 3 to 6.9 years, and the C-SSQ-C was administered to participants aged 7 to 18 years. The internal consistency, test-retest reliability, and validity were evaluated for both questionnaires.\nRESULTS: Both C-SSQ-P and C-SSQ-C demonstrated high internal consistency (Cronbach's α >0.8) and good validity (generalized linear model revealed significant negative relationships between the C-SSQ-P subscales with aided better-hearing threshold [β = -0.08 to -0.12, p ≤ 0.001] and between the C-SSQ-C subscales with worse-hearing threshold [β = -0.13 to -0.14, p < 0.001]). Among the children with HL, the participants with bilateral cochlear implants had demonstrated better performance than those with bimodal hearing and bilateral hearing aids, as evidenced by the highest mean scores in three subscales.\nCONCLUSIONS: Both C-SSQ-P and C-SSQ-C are reliable and valid for assessing HL in children and adolescents. The C-SSQ-P is applicable in evaluating young children aged 3 to 6.9 years after a 7-day observation period, while the C-SSQ-C is appropriate for children and adolescents aged 7 to 18 years.\nPMID:\n38831494\n| DOI:\n10.1097/AUD.0000000000001525"
            },
            {
                "title": "Effectiveness of the HEAR-Aware App for Adults Not Ready for Hearing Aids, but Open to Self-Management Support: Results of a Randomized Controlled Trial",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38831480/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.922424",
                "summary": "INTRODUCTION: Recently, the HEAR-aware app was developed to support adults who are eligible for hearing aids (HAs) but not yet ready to use them. The app serves as a self-management tool, offering assistance for a range of target behaviors (TBs), such as communication strategies and emotional coping. Using ecological momentary assessment and intervention, the app prompts users to complete brief surveys regarding challenging listening situations they encounter in their daily lives (ecological...",
                "full_content": "Ear Hear\n. 2024 Jun 4. doi: 10.1097/AUD.0000000000001533. Online ahead of print.\nABSTRACT\nINTRODUCTION: Recently, the HEAR-aware app was developed to support adults who are eligible for hearing aids (HAs) but not yet ready to use them. The app serves as a self-management tool, offering assistance for a range of target behaviors (TBs), such as communication strategies and emotional coping. Using ecological momentary assessment and intervention, the app prompts users to complete brief surveys regarding challenging listening situations they encounter in their daily lives (ecological momentary assessment). In response, users receive educational content in the form of \"snippets\" (videos, texts, web links) on the TBs, some of which are customized based on the reported acoustic environmental characteristics (ecological momentary intervention). The primary objective of this study was to assess the effectiveness of the HEAR-aware app in enhancing readiness to take action on various TBs and evaluate its impact on secondary outcomes. The secondary objective was to examine the app's usability, usefulness, and user satisfaction.\nMETHODS: A randomized controlled trial design with two arms was used. Participants with hearing loss aged 50 years and over were recruited via an HA retailer and randomly assigned to the intervention group (n = 42, mean age = 65 years [SD = 9.1]) or the control group (n = 45, mean age = 68 years [SD 8.7]). The intervention group used the app during 4 weeks. The control group received no intervention. All participants completed online questionnaires at baseline (T0), after 4 weeks (T1), and again 4 weeks later (T2). Participants' readiness to take action on five TBs was measured with The Line Composite. A list of secondary outcomes was used. Intention-to-treat analyses were performed using Linear Mixed effect Models including group (intervention/control), time (T0/T1/T2), and Group × Time Interactions. In addition, a per protocol analysis was carried out to explore whether effects depended on app usage. For the secondary aim the System Usability Scale (SUS), the Intrinsic Motivation Inventory, item 4 of the International Outcome Inventory-Alternative Intervention (IOI-AI), and a recommendation item were used (intervention group only at T1).\nRESULTS: For objective 1, there was no significant group difference for The Line Composite over the course of T0, T1, and T2. However, a significant (p = 0.033) Group × Time Interaction was found for The Line Emotional coping, with higher increase in readiness to take action on emotional coping in the intervention group than in the control group. The intention-to-treat analyses revealed no other significant group differences, but the per protocol analyses showed that participants in the intervention group were significantly more ready to take up Assistive Listening Devices (The Line Assistive Listening Devices) and less ready to take up HAs (Staging Algorithm HAs) than the control group (p = 0.049). Results for objective 2 showed that on average, participants rated the app as moderately useful (mean Intrinsic Motivation Inventory score 5 out of 7) and its usability as \"marginal\" (mean SUS score 68 out of 100) with about half of the participants rating the app as \"good\" (SUS score >70) and a minority rating is as \"unacceptable\" (SUS score ≤50).\nDISCUSSION/CONCLUSIONS: This study underscores the potential of self-management support tools like the HEAR-aware app in the rehabilitation of adults with hearing loss who are not yet ready for HAs. The range in usability scores suggest that it may not be a suitable intervention for everyone.\nPMID:\n38831480\n| DOI:\n10.1097/AUD.0000000000001533"
            },
            {
                "title": "Task-Specific Rapid Auditory Perceptual Learning in Adult Cochlear Implant Recipients: What Could It Mean for Speech Recognition",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38829780/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.922777",
                "summary": "CONCLUSIONS: Consistent with previous findings in other populations, in CI recipients, early task-specific rapid auditory perceptual, learning also accounts for some of the individual differences in the recognition of speech in noise and natural-fast speech in quiet. Thus, across populations, the early rapid adaptation phase of task-specific rapid auditory perceptual learning might serve as a skill that supports speech recognition in various adverse conditions. In CI users, the ability to...",
                "full_content": "Ear Hear\n. 2024 May 29. doi: 10.1097/AUD.0000000000001523. Online ahead of print.\nABSTRACT\nOBJECTIVES: Speech recognition in cochlear implant (CI) recipients is quite variable, particularly in challenging listening conditions. Demographic, audiological, and cognitive factors explain some, but not all, of this variance. The literature suggests that rapid auditory perceptual learning explains unique variance in speech recognition in listeners with normal hearing and those with hearing loss. The present study focuses on the early adaptation phase of task-specific rapid auditory perceptual learning. It investigates whether adult CI recipients exhibit this learning and, if so, whether it accounts for portions of the variance in their recognition of fast speech and speech in noise.\nDESIGN: Thirty-six adult CI recipients (ages = 35 to 77, M = 55) completed a battery of general speech recognition tests (sentences in speech-shaped noise, four-talker babble noise, and natural-fast speech), cognitive measures (vocabulary, working memory, attention, and verbal processing speed), and a rapid auditory perceptual learning task with time-compressed speech. Accuracy in the general speech recognition tasks was modeled with a series of generalized mixed models that accounted for demographic, audiological, and cognitive factors before accounting for the contribution of task-specific rapid auditory perceptual learning of time-compressed speech.\nRESULTS: Most CI recipients exhibited early task-specific rapid auditory perceptual learning of time-compressed speech within the course of the first 20 sentences. This early task-specific rapid auditory perceptual learning had unique contribution to the recognition of natural-fast speech in quiet and speech in noise, although the contribution to natural-fast speech may reflect the rapid learning that occurred in this task. When accounting for demographic and cognitive characteristics, an increase of 1 SD in the early task-specific rapid auditory perceptual learning rate was associated with ~52% increase in the odds of correctly recognizing natural-fast speech in quiet, and ~19% to 28% in the odds of correctly recognizing the different types of speech in noise. Age, vocabulary, attention, and verbal processing speed also had unique contributions to general speech recognition. However, their contribution varied between the different general speech recognition tests.\nCONCLUSIONS: Consistent with previous findings in other populations, in CI recipients, early task-specific rapid auditory perceptual, learning also accounts for some of the individual differences in the recognition of speech in noise and natural-fast speech in quiet. Thus, across populations, the early rapid adaptation phase of task-specific rapid auditory perceptual learning might serve as a skill that supports speech recognition in various adverse conditions. In CI users, the ability to rapidly adapt to ongoing acoustical challenges may be one of the factors associated with good CI outcomes. Overall, CI recipients with higher cognitive resources and faster rapid learning rates had better speech recognition.\nPMID:\n38829780\n| DOI:\n10.1097/AUD.0000000000001523"
            },
            {
                "title": "Hearing Loss and Dementia: Where to From Here?: Erratum",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38825741/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.923037",
                "summary": "No abstract",
                "full_content": "Ear Hear\n. 2024 Jun 3. doi: 10.1097/AUD.0000000000001521. Online ahead of print.\nNO ABSTRACT\nPMID:\n38825741\n| DOI:\n10.1097/AUD.0000000000001521"
            },
            {
                "title": "Quick Estimation of Minimum Hearing Levels Using a Binaural Multifrequency Stimulus Paradigm: Proof of Concept",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38825740/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.923385",
                "summary": "CONCLUSIONS: Our novel and simple paradigm using either NB iChirps or tone-bursts provides a reliable method to rapidly estimate the minimum hearing levels across audiometric frequencies for both ears. Incorporation of an automatic wave V detection algorithm increases objectivity and further reduce test time and facilitate early hearing identification and intervention.",
                "full_content": "Ear Hear\n. 2024 Jun 3. doi: 10.1097/AUD.0000000000001535. Online ahead of print.\nABSTRACT\nOBJECTIVES: Objective estimation of minimum hearing levels using auditory brainstem responses (ABRs) elicited by single frequency tone-bursts presented monaurally is currently considered the gold standard. However, the data acquisition time to estimate thresholds (for both ears across four audiometric frequencies) using this method usually exceeds the sleep time (ranging between 35 and 49 minutes) in infants below 4 months, thus providing incomplete information of hearing status which in turn delays timely clinical intervention. Alternate approaches using faster rate, or tone-burst trains have not been readily accepted due to additional hardware and software requirements. We propose here a novel binaural multifrequency stimulation paradigm wherein several stimuli of different frequencies are presented binaurally in an interleaved manner. The rationale here is that the proposed paradigm will increase acquisition efficiency, significantly reduce test time, and improve accuracy by incorporating an automatic wave V detection algorithm. It is important to note that this paradigm can be easily implemented in most commercial ABR systems currently used by most clinicians.\nDESIGN: Using this binaural multifrequency paradigm, ear specific ABRs were recorded in 30 normal-hearing young adults to both tone-bursts, and narrow-band (NB) iChirps at 500, 1000, 2000, and 4000 Hz. Comparison of ABRs elicited by tone-bursts and narrow-band chirps allowed us to determine if NB iChirps elicited a more robust wave V component compared with the tone-bursts. ABR data were characterized by measures of minimum hearing levels; wave V amplitude; and response detectability for two electrode configurations (high forehead-C7; and high forehead-linked mastoids).\nRESULTS: Consistent with the research literature, wave V response amplitudes were relatively more robust for NB iChirp stimuli compared with tone-burst stimuli. The easier identification and better detectability of wave V for the NB iChirps at lower stimulus levels contributed to their better thresholds compared with tone-burst elicited responses. It is important to note that binaural multifrequency hearing levels close to minimum hearing levels were determined in approximately 22 minutes using this paradigm-appreciably quicker than the 45 to 60 minutes or longer time required for threshold determination using the conventional single frequency method.\nCONCLUSIONS: Our novel and simple paradigm using either NB iChirps or tone-bursts provides a reliable method to rapidly estimate the minimum hearing levels across audiometric frequencies for both ears. Incorporation of an automatic wave V detection algorithm increases objectivity and further reduce test time and facilitate early hearing identification and intervention.\nPMID:\n38825740\n| DOI:\n10.1097/AUD.0000000000001535"
            },
            {
                "title": "A Multi-Sample Comparison and Rasch Analysis of the Evaluation of Children's Listening and Processing Skills Questionnaire",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38825739/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=8005585&fc=None&ff=20240625093644&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:45.923738",
                "summary": "CONCLUSIONS: Across the languages assessed here, the ECLiPS caregiver questionnaire was verified to be a psychometrically valid qualitative measure to assess listening and processing skills, which can be used to support the assessment and management of elementary school children referred with LiD.",
                "full_content": "Ear Hear\n. 2024 Jun 3. doi: 10.1097/AUD.0000000000001509. Online ahead of print.\nABSTRACT\nOBJECTIVES: Assessing listening difficulties and associated complaints can be challenging. Often, measures of peripheral auditory functions are within normal ranges, making clinicians feel unsure about proper management strategies. The range and nature of observed or experienced difficulties might be better captured using a qualitative measure. The Evaluation of Children's Listening and Processing Skills (ECLiPS) questionnaire was designed to broadly profile the auditory and cognitive problems often present in children with listening difficulties. This 38-item questionnaire was initially standardized in British children aged 6 to 11 years, was subsequently modified for use with North-American children, and was recently translated into Flemish-Dutch. This study aimed to compare typical scores of the Flemish version with the UK and US versions, and to evaluate and compare its psychometric quality based on Rasch analysis.\nDESIGN: We selected 112 Flemish children aged 6 to 11 years with verified normal hearing and typical development, and asked two caregivers of every child to fill out the ECLiPS. Data from two comparator samples were analyzed, including responses for 71 North-American children and 650 British children. Typical values for ECLiPS factors and aggregates were determined as a function of age and gender, and meaningful differences across samples were analyzed. Rasch analyses were performed to evaluate whether ECLiPS response categories work as intended, and whether item scores fit a linear equal interval measurement scale that works the same way for everyone. Item and person metrics were derived, including separation and reliability indices. We investigated whether items function similarly across linguistically and culturally different samples.\nRESULTS: ECLiPS scores were relatively invariant to age. Girls obtained higher scores compared with boys, mainly for items related to memory and attention, and pragmatic and social skills. Across ECLiPS versions, the most pronounced differences were found for items probing social skills. With respect to its psychometric quality, ECLiPS response categories work as intended, and ECLiPS items were found to fit the Rasch measurement scale. Cultural differences in responses were noted for some items, belonging to different factors. Item separation and reliability indices generally pointed toward sufficient variation in item difficulty. In general, person separation (and reliability) metrics, quantifying the instrument's ability to distinguish between poor and strong performers (in a reproducible manner), were low. This is expected from samples of typically developing children with homogeneous and high levels of listening ability.\nCONCLUSIONS: Across the languages assessed here, the ECLiPS caregiver questionnaire was verified to be a psychometrically valid qualitative measure to assess listening and processing skills, which can be used to support the assessment and management of elementary school children referred with LiD.\nPMID:\n38825739\n| DOI:\n10.1097/AUD.0000000000001509"
            }
        ]
    },
    "Hear Res": {
        "feed_title": "Hear Res",
        "feed_link": "https://pubmed.ncbi.nlm.nih.gov/?sort=date&term=7900445%20%5BNLMID%5D&v=2.18.0.post9+e462414&ff=20240625093646&utm_content=7900445&utm_campaign=journals&utm_source=Other&utm_medium=rss&fc=None",
        "feed_updated": "Tue, 25 Jun 2024 13:36:48 +0000",
        "entries": [
            {
                "title": "A burden shared: The evolutionary case for studying human deafness in Drosophila",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38896942/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.345577",
                "summary": "Hearing impairment is the most prevalent sensory disease in humans and can have dramatic effects on the development, and preservation, of our cognitive abilities and social interactions. Currently 20 % of the world's population suffer from a form of hearing impairment; this is predicted to rise to 25 % by 2050. Despite this staggering disease load, and the vast damage it inflicts on the social, medical and economic fabric of humankind, our ability to predict, or prevent, the loss of hearing is...",
                "full_content": "Hear Res\n. 2024 Jun 15;450:109047. doi: 10.1016/j.heares.2024.109047. Online ahead of print.\nABSTRACT\nHearing impairment is the most prevalent sensory disease in humans and can have dramatic effects on the development, and preservation, of our cognitive abilities and social interactions. Currently 20 % of the world's population suffer from a form of hearing impairment; this is predicted to rise to 25 % by 2050. Despite this staggering disease load, and the vast damage it inflicts on the social, medical and economic fabric of humankind, our ability to predict, or prevent, the loss of hearing is very poor indeed. We here make the case for a paradigm shift in our approach to studying deafness. By exploiting more forcefully the molecular-genetic conservation between human hearing and hearing in morphologically distinct models, such as the fruit fly Drosophila melanogaster, we believe, a deeper understanding of hearing and deafness can be achieved. An understanding that moves beyond the surface of the 'deafness genes' to probe the underlying bedrock of hearing, which is shared across taxa, and partly shared across modalities. When it comes to understanding the workings (and failings) of human sensory function, a simple fruit fly has a lot to offer and a fly eye might sometimes be a powerful model for a human ear. Particularly the use of fly avatars, in which specific molecular (genetic or proteomic) states of humans (e.g. specific patients) are experimentally reproduced, in order to study the corresponding molecular mechanisms (e.g. specific diseases) in a controlled yet naturalistic environment, is a tool that promises multiple unprecedented insights. The use of the fly - and fly avatars - would benefit humans and will help enhance the power of other scientific models, such as the mouse.\nPMID:\n38896942\n| DOI:\n10.1016/j.heares.2024.109047"
            },
            {
                "title": "Midbrain sensitivity to auditory motion studied with dichotic sweeps of broadband noise",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38889563/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.345864",
                "summary": "Many neurons in the central nucleus of the inferior colliculus (IC) show sensitivity to interaural time differences (ITDs), which is thought to be relayed from the brainstem. However, studies with interaural phase modulation of pure tones showed that IC neurons have a sensitivity to changes in ITD that is not present at the level of the brainstem. This sensitivity has been interpreted as a form of sensitivity to motion. A new type of stimulus is used here to study the sensitivity of IC neurons...",
                "full_content": "Hear Res\n. 2024 Jun 6;450:109066. doi: 10.1016/j.heares.2024.109066. Online ahead of print.\nABSTRACT\nMany neurons in the central nucleus of the inferior colliculus (IC) show sensitivity to interaural time differences (ITDs), which is thought to be relayed from the brainstem. However, studies with interaural phase modulation of pure tones showed that IC neurons have a sensitivity to changes in ITD that is not present at the level of the brainstem. This sensitivity has been interpreted as a form of sensitivity to motion. A new type of stimulus is used here to study the sensitivity of IC neurons to dynamic changes in ITD, in which broad- or narrowband stimuli are swept through a range of ITDs with arbitrary start-ITD, end-ITD, speed, and direction. Extracellular recordings were obtained under barbiturate anesthesia in the cat. We applied the same analyses as previously introduced for the study of responses to tones. We find effects of motion which are similar to those described in response to interaural phase modulation of tones. The size of the effects strongly depended on the motion parameters but was overall smaller than reported for tones. We found that the effects of motion could largely be explained by the temporal response pattern of the neuron such as adaptation and build-up. Our data add to previous evidence questioning true coding of motion at the level of the IC.\nPMID:\n38889563\n| DOI:\n10.1016/j.heares.2024.109066"
            },
            {
                "title": "Association of domain-general speed of information processing with spoken language outcomes in prelingually-deaf children with cochlear implants",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38889562/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.346135",
                "summary": "Spoken language development after pediatric cochlear implantation requires rapid and efficient processing of novel, degraded auditory signals and linguistic information. These demands for rapid adaptation tax the information processing speed ability of children who receive cochlear implants. This study investigated the association of speed of information processing ability with spoken language outcomes after cochlear implantation in prelingually deaf children aged 4-6 years. Two domain-general...",
                "full_content": "Hear Res\n. 2024 Jun 14;450:109069. doi: 10.1016/j.heares.2024.109069. Online ahead of print.\nABSTRACT\nSpoken language development after pediatric cochlear implantation requires rapid and efficient processing of novel, degraded auditory signals and linguistic information. These demands for rapid adaptation tax the information processing speed ability of children who receive cochlear implants. This study investigated the association of speed of information processing ability with spoken language outcomes after cochlear implantation in prelingually deaf children aged 4-6 years. Two domain-general (visual, non-linguistic) speed of information processing measures were administered to 21 preschool-aged children with cochlear implants and 23 normal-hearing peers. Measures of speech recognition, language (vocabulary and comprehension), nonverbal intelligence, and executive functioning skills were also obtained from each participant. Speed of information processing was positively associated with speech recognition and language skills in preschool-aged children with cochlear implants but not in normal-hearing peers. This association remained significant after controlling for hearing group, age, nonverbal intelligence, and executive functioning skills. These findings are consistent with models suggesting that domain-general, fast-efficient information processing speed underlies adaptation to speech perception and language learning following implantation. Assessment and intervention strategies targeting speed of information processing may provide better understanding and development of speech-language skills after cochlear implantation.\nPMID:\n38889562\n| DOI:\n10.1016/j.heares.2024.109069"
            },
            {
                "title": "Exploring auditory temporal resolution and dichotic listening skills among individuals with type 2 diabetes mellitus",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38870778/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.346420",
                "summary": "The study aimed to explore the auditory temporal resolution and dichotic listening skills in patients with type 2 diabetes mellitus (T2DM) and identify associated health-related factors. Using a cross-sectional design, 87 adults with T2DM and 48 non-diabetic controls, all with normal hearing, participated. The two central auditory processing (CAP) skills were assessed through the Gaps-In-Noise (GIN) and Dichotic-Digits Listening (DDL) tests. T2DM participants underwent blood tests to measure...",
                "full_content": "Hear Res\n. 2024 Jun 3;450:109067. doi: 10.1016/j.heares.2024.109067. Online ahead of print.\nABSTRACT\nThe study aimed to explore the auditory temporal resolution and dichotic listening skills in patients with type 2 diabetes mellitus (T2DM) and identify associated health-related factors. Using a cross-sectional design, 87 adults with T2DM and 48 non-diabetic controls, all with normal hearing, participated. The two central auditory processing (CAP) skills were assessed through the Gaps-In-Noise (GIN) and Dichotic-Digits Listening (DDL) tests. T2DM participants underwent blood tests to measure various health-related factors. In the GIN test, the shortest gap threshold (GapTh) obtained across both ears was significantly higher in the diabetic group (9.1 ± 2.4 ms) compared to the non-diabetic group (7.5 ± 1.5 ms), and the score of correctly identified gaps (GapSc) in the diabetic group (45±11 %) was significantly lower than GapSc in the non-diabetic group (52±9 %), p < 0.001. In the DDL test, the free-recall score (73.8 ± 18.5 %) across both ears and the right-ear advantage (-1.3 ± 20.6 %) in the diabetic group were significantly lower than the free-recall score (85.8 ± 11.9 %) and right-ear advantage (6.9 ± 11.9 %) in the non-diabetic group, p < 0.005. Furthermore, the duration of diabetes, eGFR level, retinopathy, carotid plaque, fasting blood glucose level, and HDL-C (good cholesterol) level were factors significantly associated with performances in the GIN and/or DDL tests for T2DM participants. In conclusion, individuals with T2DM are at risk of reduced auditory processing skills in temporal resolution and dichotic listening, impacting their speech understanding. Six health-related factors were identified as significantly associated with CAP skills in T2DM patients.\nPMID:\n38870778\n| DOI:\n10.1016/j.heares.2024.109067"
            },
            {
                "title": "Mfsd2a regulates the blood-labyrinth-barrier formation and function through tight junctions and transcytosis",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38852535/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.346687",
                "summary": "The Blood-Labyrinth Barrier (BLB) is pivotal for the maintenance of lymphatic homeostasis within the inner ear, yet the intricacies of its development and function are inadequately understood. The present investigation delves into the contribution of the Mfsd2a molecule, integral to the structural and functional integrity of the Blood-Brain Barrier (BBB), to the ontogeny and sustenance of the BLB. Our empirical findings delineate that the maturation of the BLB in murine models is not realized...",
                "full_content": "Hear Res\n. 2024 May 28;450:109048. doi: 10.1016/j.heares.2024.109048. Online ahead of print.\nABSTRACT\nThe Blood-Labyrinth Barrier (BLB) is pivotal for the maintenance of lymphatic homeostasis within the inner ear, yet the intricacies of its development and function are inadequately understood. The present investigation delves into the contribution of the Mfsd2a molecule, integral to the structural and functional integrity of the Blood-Brain Barrier (BBB), to the ontogeny and sustenance of the BLB. Our empirical findings delineate that the maturation of the BLB in murine models is not realized until approximately two weeks post-birth, with preceding stages characterized by notable permeability. Transcriptomic analysis elucidates a marked augmentation in Mfsd2a expression within the lateral wall of the cochlea in specimens exhibiting an intact BLB. Moreover, both in vitro and in vivo assays substantiate that a diminution in Mfsd2a expression detrimentally impacts BLB permeability and structural integrity, principally via the attenuation of tight junction protein expression and the enhancement of endothelial cell transcytosis. These insights underscore the indispensable role of Mfsd2a in ensuring BLB integrity and propose it as a viable target for therapeutic interventions aimed at the amelioration of hearing loss.\nPMID:\n38852535\n| DOI:\n10.1016/j.heares.2024.109048"
            },
            {
                "title": "The role of hidden hearing loss in tinnitus: Insights from early markers of peripheral hearing damage",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38852534/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.346981",
                "summary": "Since the presence of tinnitus is not always associated with audiometric hearing loss, it has been hypothesized that hidden hearing loss may act as a potential trigger for increased central gain along the neural pathway leading to tinnitus perception. In recent years, the study of hidden hearing loss has improved with the discovery of cochlear synaptopathy and several objective diagnostic markers. This study investigated three potential markers of peripheral hidden hearing loss in subjects with...",
                "full_content": "Hear Res\n. 2024 Jun 1;450:109050. doi: 10.1016/j.heares.2024.109050. Online ahead of print.\nABSTRACT\nSince the presence of tinnitus is not always associated with audiometric hearing loss, it has been hypothesized that hidden hearing loss may act as a potential trigger for increased central gain along the neural pathway leading to tinnitus perception. In recent years, the study of hidden hearing loss has improved with the discovery of cochlear synaptopathy and several objective diagnostic markers. This study investigated three potential markers of peripheral hidden hearing loss in subjects with tinnitus: extended high-frequency audiometric thresholds, the auditory brainstem response, and the envelope following response. In addition, speech intelligibility was measured as a functional outcome measurement of hidden hearing loss. To account for age-related hidden hearing loss, participants were grouped according to age, presence of tinnitus, and audiometric thresholds. Group comparisons were conducted to differentiate between age- and tinnitus-related effects of hidden hearing loss. All three markers revealed age-related differences, whereas no differences were observed between the tinnitus and non-tinnitus groups. However, the older tinnitus group showed improved performance on low-pass filtered speech in noise tests compared to the older non-tinnitus group. These low-pass speech in noise scores were significantly correlated with tinnitus distress, as indicated using questionnaires, and could be related to the presence of hyperacusis. Based on our observations, cochlear synaptopathy does not appear to be the underlying cause of tinnitus. The improvement in low-pass speech-in-noise could be explained by enhanced temporal fine structure encoding or hyperacusis. Therefore, we recommend that future tinnitus research takes into account age-related factors, explores low-frequency encoding, and thoroughly assesses hyperacusis.\nPMID:\n38852534\n| DOI:\n10.1016/j.heares.2024.109050"
            },
            {
                "title": "The impact of round window reinforcement on middle and inner ear mechanics with air and bone conduction stimulation",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38850830/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.347595",
                "summary": "The round window (RW) membrane plays an important role in normal inner ear mechanics. Occlusion or reinforcement of the RW has been described in the context of congenital anomalies or after cochlear implantation and is applied as a surgical treatment for hyperacusis. Multiple lumped and finite element models predict a low-frequency hearing loss with air conduction of up to 20 dB after RW reinforcement and limited to no effect on hearing with bone conduction stimulation. Experimental verification...",
                "full_content": "Hear Res\n. 2024 May 31;450:109049. doi: 10.1016/j.heares.2024.109049. Online ahead of print.\nABSTRACT\nThe round window (RW) membrane plays an important role in normal inner ear mechanics. Occlusion or reinforcement of the RW has been described in the context of congenital anomalies or after cochlear implantation and is applied as a surgical treatment for hyperacusis. Multiple lumped and finite element models predict a low-frequency hearing loss with air conduction of up to 20 dB after RW reinforcement and limited to no effect on hearing with bone conduction stimulation. Experimental verification of these results, however, remains limited. Here, we present an experimental study measuring the impact of RW reinforcement on the middle and inner ear mechanics with air and bone conduction stimulation. In a within-specimen repeated measures design with human cadaveric specimens (n = 6), we compared the intracochlear pressures in scala vestibuli (P\nSV\n) and scala tympani (P\nST\n) before and after RW reinforcement with soft tissue, cartilage, and bone cement. The differential pressure (P\nDIFF\n) across the basilar membrane - known to be closely related to the hearing sensation - was calculated as the complex difference between P\nSV\nand P\nST\n. With air conduction stimulation, both P\nSV\nand P\nST\nincreased on average up to 22 dB at frequencies below 1500 Hz with larger effect sizes for P\nST\ncompared to P\nSV\n. The P\nDIFF\n, in contrast, decreased up to 11 dB at frequencies between 700 and 800 Hz after reinforcement with bone cement. With bone conduction, the average within-specimen effects were less than 5 dB for either P\nSV\n, P\nST,\nor P\nDIFF\n. The inter-specimen variability with bone conduction, however, was considerably larger than with air conduction. This experimental study shows that RW reinforcement impacts air conduction stimulation at low frequencies. Bone conduction stimulation seems to be largely unaffected. From a clinical point of view, these results support the hypothesis that delayed loss of air conduction hearing after cochlear implantation could be partially explained by the impact of RW reinforcement.\nPMID:\n38850830\n| DOI:\n10.1016/j.heares.2024.109049"
            },
            {
                "title": "miR-130b-3p involved in the pathogenesis of age-related hearing loss via targeting PPARγ and autophagy",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38820739/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.348061",
                "summary": "The study focuses on the underlying regulatory mechanism of age-related hearing loss (ARHL), which results from autophagy dysregulation mediated by miR-130b-3p targeting PPARγ. We constructed miR-130b-3p knockout (antagomir) and PPARγ over-expression (OE-PPARγ) mice model by injecting mmu-miR-130b-3p antagomir and HBAAV2/Anc80-m-Pparg-T2A-mCHerry into the right ear' round window of each mouse, respectively. In vitro, we introduced oxidative stress within HEI-OC1 cells by H(2)O(2) and exogenously...",
                "full_content": "Hear Res\n. 2024 Aug;449:109029. doi: 10.1016/j.heares.2024.109029. Epub 2024 May 20.\nABSTRACT\nThe study focuses on the underlying regulatory mechanism of age-related hearing loss (ARHL), which results from autophagy dysregulation mediated by miR-130b-3p targeting PPARγ. We constructed miR-130b-3p knockout (antagomir) and PPARγ over-expression (OE-PPARγ) mice model by injecting mmu-miR-130b-3p antagomir and HBAAV2/Anc80-m-Pparg-T2A-mCHerry into the right ear' round window of each mouse, respectively. In vitro, we introduced oxidative stress within HEI-OC1 cells by H\n2\nO\n2\nand exogenously changed the miR-130b-3p and PPARγ levels. MiRNA level was detected by RT-qPCR, proteins by western blotting and immunohistochemistry. Morphology of autophagosomes was observed by electron microscopy. In vivo, the cochlea of aged mice showed higher miR-130b-3p expression and lower PPARγ expression, while exogenous inhibition of miR-130b-3p up-regulated PPARγ expression. Autophagy-related biomarkers expression (ATG5, Beclin-1 and LC3B II/I) decreased in aged mice, which reversely increased after the inhibition of miR-130b-3p. The elevation of PPARγ demonstrated similar effects. Contrarily, exogenous overexpression of miR-130b-3p resulted in the decrease of ATG5, Beclin-1 and LC3B II/I. We created oxidative stress within HEI-OC1 by H\n2\nO\n2\n, subsequently observed the formation of autophagosomes under electron microscope, so as the elevated cell apoptosis rate and weakened cell viability. MiR-130b-3p/PPARγ contributed to the premature senescence of these H\n2\nO\n2\n-induced HEI-OC1 cells. MiR-130b-3p regulated HEI-OC1 cell growth by targeting PPARγ, thus leading to ARHL.\nPMID:\n38820739\n| DOI:\n10.1016/j.heares.2024.109029"
            },
            {
                "title": "Tinnitus mechanisms and the need for an objective electrophysiological tinnitus test",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38810373/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.348329",
                "summary": "Tinnitus, the perception of sound with no external auditory stimulus, is a complex, multifaceted, and potentially devastating disorder. Despite recent advances in our understanding of tinnitus, there are limited options for effective treatment. Tinnitus treatments are made more complicated by the lack of a test for tinnitus based on objectively measured physiological characteristics. Such an objective test would enable a greater understanding of tinnitus mechanisms and may lead to faster...",
                "full_content": "Hear Res\n. 2024 Aug;449:109046. doi: 10.1016/j.heares.2024.109046. Epub 2024 May 23.\nABSTRACT\nTinnitus, the perception of sound with no external auditory stimulus, is a complex, multifaceted, and potentially devastating disorder. Despite recent advances in our understanding of tinnitus, there are limited options for effective treatment. Tinnitus treatments are made more complicated by the lack of a test for tinnitus based on objectively measured physiological characteristics. Such an objective test would enable a greater understanding of tinnitus mechanisms and may lead to faster treatment development in both animal and human research. This review makes the argument that an objective tinnitus test, such as a non-invasive electrophysiological measure, is desperately needed. We review the current tinnitus assessment methods, the underlying neural correlates of tinnitus, the multiple tinnitus generation theories, and the previously investigated electrophysiological measurements of tinnitus. Finally, we propose an alternate objective test for tinnitus that may be valid in both animal and human subjects.\nPMID:\n38810373\n| DOI:\n10.1016/j.heares.2024.109046"
            },
            {
                "title": "Medial superior olive in the rat: Anatomy, sources of input and axonal projections",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38797037/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.348601",
                "summary": "Although rats and mice are among the preferred animal models for investigating many characteristics of auditory function, they are rarely used to study an essential aspect of binaural hearing: the ability of animals to localize the sources of low-frequency sounds by detecting the interaural time difference (ITD), that is the difference in the time at which the sound arrives at each ear. In mammals, ITDs are mostly encoded in the medial superior olive (MSO), one of the main nuclei of the superior...",
                "full_content": "Hear Res\n. 2024 Aug;449:109036. doi: 10.1016/j.heares.2024.109036. Epub 2024 May 25.\nABSTRACT\nAlthough rats and mice are among the preferred animal models for investigating many characteristics of auditory function, they are rarely used to study an essential aspect of binaural hearing: the ability of animals to localize the sources of low-frequency sounds by detecting the interaural time difference (ITD), that is the difference in the time at which the sound arrives at each ear. In mammals, ITDs are mostly encoded in the medial superior olive (MSO), one of the main nuclei of the superior olivary complex (SOC). Because of their small heads and high frequency hearing range, rats and mice are often considered unable to use ITDs for sound localization. Moreover, their MSO is frequently viewed as too small or insignificant compared to that of mammals that use ITDs to localize sounds, including cats and gerbils. However, recent research has demonstrated remarkable similarities between most morphological and physiological features of mouse MSO neurons and those of MSO neurons of mammals that use ITDs. In this context, we have analyzed the structure and neural afferent and efferent connections of the rat MSO, which had never been studied by injecting neuroanatomical tracers into the nucleus. The rat MSO spans the SOC longitudinally. It is relatively small caudally, but grows rostrally into a well-developed column of stacked bipolar neurons. By placing small, precise injections of the bidirectional tracer biotinylated dextran amine (BDA) into the MSO, we show that this nucleus is innervated mainly by the most ventral and rostral spherical bushy cells of the anteroventral cochlear nucleus of both sides, and by the most ventrolateral principal neurons of the ipsilateral medial nucleus of the trapezoid body. The same experiments reveal that the MSO densely innervates the most dorsolateral region of the central nucleus of the inferior colliculus, the central region of the dorsal nucleus of the lateral lemniscus, and the most lateral region of the intermediate nucleus of the lateral lemniscus of its own side. Therefore, the MSO is selectively innervated by, and sends projections to, neurons that process low-frequency sounds. The structural and hodological features of the rat MSO are notably similar to those of the MSO of cats and gerbils. While these similarities raise the question of what functions other than ITD coding the MSO performs, they also suggest that the rat MSO is an appropriate model for future MSO-centered research.\nPMID:\n38797037\n| DOI:\n10.1016/j.heares.2024.109036"
            },
            {
                "title": "Hearing loss-related altered neuronal activity in the inferior colliculus",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38797036/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.348995",
                "summary": "Hearing loss is well known to cause plastic changes in the central auditory system and pathological changes such as tinnitus and hyperacusis. Impairment of inner ear functions is the main cause of hearing loss. In aged individuals, not only inner ear dysfunction but also senescence of the central nervous system is the cause of malfunction of the auditory system. In most cases of hearing loss, the activity of the auditory nerve is reduced, but that of the successive auditory centers is increased...",
                "full_content": "Hear Res\n. 2024 Aug;449:109033. doi: 10.1016/j.heares.2024.109033. Epub 2024 May 20.\nABSTRACT\nHearing loss is well known to cause plastic changes in the central auditory system and pathological changes such as tinnitus and hyperacusis. Impairment of inner ear functions is the main cause of hearing loss. In aged individuals, not only inner ear dysfunction but also senescence of the central nervous system is the cause of malfunction of the auditory system. In most cases of hearing loss, the activity of the auditory nerve is reduced, but that of the successive auditory centers is increased in a compensatory way. It has been reported that activity changes occur in the inferior colliculus (IC), a critical nexus of the auditory pathway. The IC integrates the inputs from the brainstem and drives the higher auditory centers. Since abnormal activity in the IC is likely to affect auditory perception, it is crucial to elucidate the neuronal mechanism to induce the activity changes of IC neurons with hearing loss. This review outlines recent findings on hearing-loss-induced plastic changes in the IC and brainstem auditory neuronal circuits and discusses what neuronal mechanisms underlie hearing-loss-induced changes in the activity of IC neurons. Considering the different causes of hearing loss, we discuss age-related hearing loss separately from other forms of hearing loss (non-age-related hearing loss). In general, the main plastic change of IC neurons caused by both age-related and non-age-related hearing loss is increased central gain. However, plastic changes in the IC caused by age-related hearing loss seem to be more complex than those caused by non-age-related hearing loss.\nPMID:\n38797036\n| DOI:\n10.1016/j.heares.2024.109033"
            },
            {
                "title": "Congenital deafness reduces alpha-gamma cross-frequency coupling in the auditory cortex",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38797035/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.349273",
                "summary": "Neurons within a neuronal network can be grouped by bottom-up and top-down influences using synchrony in neuronal oscillations. This creates the representation of perceptual objects from sensory features. Oscillatory activity can be differentiated into stimulus-phase-locked (evoked) and non-phase-locked (induced). The former is mainly determined by sensory input, the latter by higher-level (cortical) processing. Effects of auditory deprivation on cortical oscillations have been studied in...",
                "full_content": "Hear Res\n. 2024 Aug;449:109032. doi: 10.1016/j.heares.2024.109032. Epub 2024 May 17.\nABSTRACT\nNeurons within a neuronal network can be grouped by bottom-up and top-down influences using synchrony in neuronal oscillations. This creates the representation of perceptual objects from sensory features. Oscillatory activity can be differentiated into stimulus-phase-locked (evoked) and non-phase-locked (induced). The former is mainly determined by sensory input, the latter by higher-level (cortical) processing. Effects of auditory deprivation on cortical oscillations have been studied in congenitally deaf cats (CDCs) using cochlear implant (CI) stimulation. CI-induced alpha, beta, and gamma activity were compromised in the auditory cortex of CDCs. Furthermore, top-down information flow between secondary and primary auditory areas in hearing cats, conveyed by induced alpha oscillations, was lost in CDCs. Here we used the matching pursuit algorithm to assess components of such oscillatory activity in local field potentials recorded in primary field A1. Additionally to the loss of induced alpha oscillations, we also found a loss of evoked theta activity in CDCs. The loss of theta and alpha activity in CDCs can be directly related to reduced high-frequency (gamma-band) activity due to cross-frequency coupling. Here we quantified such cross-frequency coupling in adult 1) hearing-experienced, acoustically stimulated cats (aHCs), 2) hearing-experienced cats following acute pharmacological deafening and subsequent CIs, thus in electrically stimulated cats (eHCs), and 3) electrically stimulated CDCs. We found significant cross-frequency coupling in all animal groups in > 70% of auditory-responsive sites. The predominant coupling in aHCs and eHCs was between theta/alpha phase and gamma power. In CDCs such coupling was lost and replaced by alpha oscillations coupling to delta/theta phase. Thus, alpha/theta oscillations synchronize high-frequency gamma activity only in hearing-experienced cats. The absence of induced alpha and theta oscillations contributes to the loss of induced gamma power in CDCs, thereby signifying impaired local network activity.\nPMID:\n38797035\n| DOI:\n10.1016/j.heares.2024.109032"
            },
            {
                "title": "Aging effects on the neural representation and perception of consonant transition cues",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38781768/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.349572",
                "summary": "Older listeners have difficulty processing temporal cues that are important for word discrimination, and deficient processing may limit their ability to benefit from these cues. Here, we investigated aging effects on perception and neural representation of the consonant transition and the factors that contribute to successful perception. To further understand the neural mechanisms underlying the changes in processing from brainstem to cortex, we also examined the factors that contribute to...",
                "full_content": "Hear Res\n. 2024 Jul;448:109034. doi: 10.1016/j.heares.2024.109034. Epub 2024 May 17.\nABSTRACT\nOlder listeners have difficulty processing temporal cues that are important for word discrimination, and deficient processing may limit their ability to benefit from these cues. Here, we investigated aging effects on perception and neural representation of the consonant transition and the factors that contribute to successful perception. To further understand the neural mechanisms underlying the changes in processing from brainstem to cortex, we also examined the factors that contribute to exaggerated amplitudes in cortex. We enrolled 30 younger normal-hearing and 30 older normal-hearing participants who met the criteria of clinically normal hearing. Perceptual identification functions were obtained for the words BEAT and WHEAT on a 7-step continuum of consonant-transition duration. Auditory brainstem responses (ABRs) were recorded to click stimuli and frequency-following responses (FFRs) and cortical auditory-evoked potentials were recorded to the endpoints of the BEAT-WHEAT continuum. Perceptual performance for identification of BEAT vs. WHEAT did not differ between younger and older listeners. However, both subcortical and cortical measures of neural representation showed age group differences, such that FFR phase locking was lower but cortical amplitudes (P1 and N1) were higher in older compared to younger listeners. ABR Wave I amplitude and FFR phase locking, but not audiometric thresholds, predicted early cortical amplitudes. Phase locking to the transition region and early cortical peak amplitudes (P1) predicted performance on the perceptual identification function. Overall, results suggest that the neural representation of transition durations and cortical overcompensation may contribute to the ability to perceive transition duration contrasts. Cortical overcompensation appears to be a maladaptive response to decreased neural firing/synchrony.\nPMID:\n38781768\n| PMC:\nPMC11156531\n| DOI:\n10.1016/j.heares.2024.109034"
            },
            {
                "title": "Characterizing the relationship between modulation sensitivity and pitch resolution in cochlear implant users",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38776706/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.349834",
                "summary": "Cochlear implants are medical devices that have restored hearing to approximately one million people around the world. Outcomes are impressive and most recipients attain excellent speech comprehension in quiet without relying on lip-reading cues, but pitch resolution is poor compared to normal hearing. Amplitude modulation of electrical stimulation is a primary cue for pitch perception in cochlear implant users. The experiments described in this article focus on the relationship between...",
                "full_content": "Hear Res\n. 2024 Jul;448:109026. doi: 10.1016/j.heares.2024.109026. Epub 2024 May 16.\nABSTRACT\nCochlear implants are medical devices that have restored hearing to approximately one million people around the world. Outcomes are impressive and most recipients attain excellent speech comprehension in quiet without relying on lip-reading cues, but pitch resolution is poor compared to normal hearing. Amplitude modulation of electrical stimulation is a primary cue for pitch perception in cochlear implant users. The experiments described in this article focus on the relationship between sensitivity to amplitude modulations and pitch resolution based on changes in the frequency of amplitude modulations. In the first experiment, modulation sensitivity and pitch resolution were measured in adults with no known hearing loss and in cochlear implant users with sounds presented to and processed by their clinical devices. Stimuli were amplitude-modulated sinusoids and amplitude-modulated narrow-band noises. Modulation detection and modulation frequency discrimination were measured for modulation frequencies centered on 110, 220, and 440 Hz. Pitch resolution based on changes in modulation frequency was measured for modulation depths of 25 %, 50 %, 100 %, and for a half-waved rectified modulator. Results revealed a strong linear relationship between modulation sensitivity and pitch resolution for cochlear implant users and peers with no known hearing loss. In the second experiment, cochlear implant users took part in analogous procedures of modulation sensitivity and pitch resolution but bypassing clinical sound processing using single-electrode stimulation. Results indicated that modulation sensitivity and pitch resolution was better conveyed by single-electrode stimulation than by clinical processors. Results at 440 Hz were worse, but also not well conveyed by clinical sound processing, so it remains unclear whether the 300 Hz perceptual limit described in the literature is a technological or biological limitation. These results highlight modulation depth and sensitivity as critical factors for pitch resolution in cochlear implant users and characterize the relationship that should inform the design of modulation enhancement algorithms for cochlear implants.\nPMID:\n38776706\n| DOI:\n10.1016/j.heares.2024.109026"
            },
            {
                "title": "Expression profiling of cochlear genes uncovers sex-based cellular function in mouse cochleae",
                "link": "https://pubmed.ncbi.nlm.nih.gov/38776705/?utm_source=Other&utm_medium=rss&utm_campaign=journals&utm_content=7900445&fc=None&ff=20240625093646&v=2.18.0.post9+e462414",
                "published": "2024-06-25T13:36:48.350091",
                "summary": "Sex is a pivotal biological factor that significantly impacts tissue homeostasis and disease susceptibility. In the auditory system, sex differences have been observed in cochlear physiology and responses to pathological conditions. However, the underlying molecular mechanisms responsible for these differences remain elusive. The current research explores the differences in gene expression profiles in the cochlea between male and female mice, aiming to understand the functional implication of...",
                "full_content": "Hear Res\n. 2024 Jul;448:109030. doi: 10.1016/j.heares.2024.109030. Epub 2024 May 14.\nABSTRACT\nSex is a pivotal biological factor that significantly impacts tissue homeostasis and disease susceptibility. In the auditory system, sex differences have been observed in cochlear physiology and responses to pathological conditions. However, the underlying molecular mechanisms responsible for these differences remain elusive. The current research explores the differences in gene expression profiles in the cochlea between male and female mice, aiming to understand the functional implication of sex-biased gene expression in each sex. Using RNA-sequencing analysis on cochlear tissues obtained from male and female mice, we identified a significant number of genes exhibiting sex-biased expression differences. While some of these differentially expressed genes are located on sex chromosomes, most are found on autosomal chromosomes. Further bioinformatic analysis revealed that these genes are involved in several key cellular functions. In males, these genes are notably linked to oxidative phosphorylation and RNA synthesis and processing, suggesting their involvement in mitochondrial energy production and regulatory control of gene expression. In contrast, sex-biased genes are associated with mechano-transduction and synaptic transmission within female cochleae. Collectively, our study provides valuable insights into the molecular differences between the sexes and emphasizes the need for future research to uncover their functional implications and relevance to auditory health and disease development.\nPMID:\n38776705\n| DOI:\n10.1016/j.heares.2024.109030"
            }
        ]
    }
}